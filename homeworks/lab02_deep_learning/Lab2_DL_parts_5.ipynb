{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEQXLnIvP1jP"
      },
      "source": [
        "### Part 5. Dogs classification (2+ points)\n",
        "__Disclaimer__: Это опциональная часть задания. Здесь придется экспериментировать, подбирать оптимальную структуру сети для решения задачи и активно искать подскзаки в сети.\n",
        "\n",
        "Предлагаем вам решить задачу классификации пород собак. Вы можете обучить сеть с нуля или же воспользоваться методом fine-tuning'а. Полезная ссылка на [предобученные модели](https://pytorch.org/docs/stable/torchvision/models.html).\n",
        "\n",
        "Данные можно скачать [отсюда](https://www.dropbox.com/s/vgqpz2f1lolxmlv/data.zip?dl=0). Датасет представлен 50 классами пород собак, которые можно найти в папке train в соответствующих директориях. При сдаче данной части задания вместе с ноутбуком необходимо отправить .csv-файл с предсказаниями классов тестовой выборки в формате: <имя изображения>,<метка класса> по одному объекту на строку. Ниже приведите код ваших экспериментов и короткий вывод по их результатам.\n",
        "\n",
        "Будут оцениваться качество классификации (accuracy) на тестовой выборке (2 балла) и проведенные эксперименты (1 балл).\n",
        "Разбалловка следующая:\n",
        "* $>=$93% - 2 points\n",
        "* $>=$84% - 1.5 points\n",
        "* $>=$70% - 0.75 points"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XwrTMVIIPCo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ulcEcW2ePMtr",
        "outputId": "61658a70-10da-41ba-e746-496384b19cbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wsSEi5nfznX",
        "outputId": "f5449e03-b533-4f17-9846-261b9b376f3b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/805.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/805.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m634.9/805.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.9.0 torchmetrics-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchsummary import summary\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from collections import defaultdict\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import os\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "15m8uJ0et1w0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = r\"drive/MyDrive/Datasets/Dog breeds/data/\"\n",
        "NUM_WORKERS = 2\n",
        "SIZE_H = SIZE_W = 96\n",
        "NUM_CLASSES = 50\n",
        "EPOCH_NUM = 30\n",
        "BATCH_SIZE = 256\n",
        "image_mean = [0.485, 0.456, 0.406]\n",
        "image_std  = [0.229, 0.224, 0.225]\n",
        "EMBEDDING_SIZE = 128"
      ],
      "metadata": {
        "id": "A6GduHnkuCBE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = transforms.Compose([\n",
        "    transforms.Resize((SIZE_H, SIZE_W)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(image_mean, image_std)\n",
        "])"
      ],
      "metadata": {
        "id": "Adw6B9NWuCO0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = torchvision.datasets.ImageFolder(os.path.join(DATA_PATH, 'train'), transform=transformer)"
      ],
      "metadata": {
        "id": "Z7lfmhj5w46n"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset), len(dataset.classes)"
      ],
      "metadata": {
        "id": "G6xXjRpK1yxY",
        "outputId": "d66f3ad2-1b1d-4d58-8dca-d51000455c57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7166, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset=dataset, lengths=(0.8, 0.2))"
      ],
      "metadata": {
        "id": "nEI7qy-V2Npc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset), len(val_dataset)"
      ],
      "metadata": {
        "id": "TUiykwC2_dZs",
        "outputId": "a31a2e14-44c1-40a3-f50f-7ef64bd8acf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5733, 1433)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = torchvision.datasets.ImageFolder(os.path.join(DATA_PATH, 'test'), transform=transformer)\n",
        "len(test_dataset)"
      ],
      "metadata": {
        "id": "U5pMNVdtBzU5",
        "outputId": "7de38d74-c022-4874-a97a-55fcf091a52e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1503"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_from_batch_generator(batch_gen):\n",
        "    data_batch, label_batch = next(iter(batch_gen))\n",
        "    grid_size = (3, 3)\n",
        "    f, axarr = plt.subplots(*grid_size)\n",
        "    f.set_size_inches(15,10)\n",
        "    for i in range(grid_size[0] * grid_size[1]):\n",
        "\n",
        "        # read images from batch to numpy.ndarray and change axes order [H, W, C] -> [H, W, C]\n",
        "        batch_image_ndarray = np.transpose(data_batch[i].numpy(), [1, 2, 0])\n",
        "\n",
        "        # inverse normalization for image data values back to [0,1] and clipping the values for correct pyplot.imshow()\n",
        "        src = np.clip(image_std * batch_image_ndarray + image_mean, 0, 1)\n",
        "\n",
        "        # display batch samples with labels\n",
        "        sample_title = 'Label = %d (%s)' % (label_batch[i])\n",
        "        axarr[i // grid_size[0], i % grid_size[0]].imshow(src)\n",
        "        axarr[i // grid_size[0], i % grid_size[0]].set_title(sample_title)\n",
        "    pass"
      ],
      "metadata": {
        "id": "evs-Fg-dSTu6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "class Runner():\n",
        "    def __init__(self, model, opt, device, criterion, metric, checkpoint_path=None):\n",
        "        self.model = model\n",
        "        self.opt = opt\n",
        "        self.device = device\n",
        "        self.criterion = criterion\n",
        "        self.metric = metric\n",
        "        self.checkpoint_path = checkpoint_path\n",
        "        self.epoch = 0\n",
        "        self.train_phase = True\n",
        "        self.logits = None\n",
        "        self._top_val_score = -1\n",
        "        self.log_dict = {\n",
        "            \"train_loss\": [],\n",
        "            \"val_loss\": [],\n",
        "            \"train_score\": [],\n",
        "            \"val_score\": []}\n",
        "\n",
        "    def forward(self, X_batch):\n",
        "        logits = self.model(X_batch)\n",
        "        return logits\n",
        "\n",
        "    def _run_batch(self, batch):\n",
        "        X_batch, y_batch = batch\n",
        "        X_batch = X_batch.to(self.device)\n",
        "        self.logits = self.forward(X_batch)\n",
        "\n",
        "    def _run_criterion(self, batch):\n",
        "        X_batch, y_batch = batch\n",
        "        y_batch = y_batch.to(self.device)\n",
        "        loss = self.criterion(self.logits, y_batch)\n",
        "        y_pred = torch.max(F.softmax(self.logits, dim=1), dim=1)[1]\n",
        "        score = self.metric(y_pred, y_batch)\n",
        "        return loss, score\n",
        "\n",
        "    def _run_epoch(self, loader, output_log=True):\n",
        "        ep_loss = []\n",
        "        ep_score = []\n",
        "        _phase_description = 'Training' if self.train_phase else 'Evaluation'\n",
        "        for batch in tqdm(loader, desc=_phase_description, leave=False):\n",
        "            self._run_batch(batch)\n",
        "\n",
        "            with torch.set_grad_enabled(self.train_phase):\n",
        "                loss, score = self._run_criterion(batch)\n",
        "\n",
        "            if self.train_phase:\n",
        "                loss.backward()\n",
        "                self.opt.step()\n",
        "                self.opt.zero_grad()\n",
        "\n",
        "            ep_loss.append(loss.item())\n",
        "            ep_score.append(score.item())\n",
        "\n",
        "        if self.train_phase:\n",
        "            self.log_dict['train_loss'].append(np.mean(ep_loss))\n",
        "            self.log_dict['train_score'].append(np.mean(ep_score))\n",
        "        else:\n",
        "            self.log_dict['val_loss'].append(np.mean(ep_loss))\n",
        "            self.log_dict['val_score'].append(np.mean(ep_score))\n",
        "\n",
        "        if output_log:\n",
        "            self.output_log()\n",
        "\n",
        "    def seve_checkpoint(self):\n",
        "        val_score = self.log_dict['val_score'][-1]\n",
        "        if val_score > self._top_val_score and self.checkpoint_path is not None:\n",
        "            self._top_val_score = val_score\n",
        "            torch.save(self.model, open(self.checkpoint_path, 'wb'))\n",
        "\n",
        "    def load_checkpoint(self):\n",
        "        if self.checkpoint_path is not None:\n",
        "            self.model = torch.load(self.checkpoint_path)\n",
        "\n",
        "    def output_log(self):\n",
        "        if self.visualize:\n",
        "            clear_output()\n",
        "\n",
        "        phase = 'Training' if self.train_phase else 'Evaluation'\n",
        "\n",
        "        print(f'{phase}: ', end='')\n",
        "        print(f'Train loss: {self.log_dict[\"train_loss\"][-1]}; Train score: {self.log_dict[\"train_score\"][-1]}')\n",
        "        print(f'Train loss: {self.log_dict[\"val_loss\"][-1]}; Train score: {self.log_dict[\"val_score\"][-1]}')\n",
        "\n",
        "        self.save_checkpoint()\n",
        "\n",
        "        if self.visualize:\n",
        "            fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "            axes[0].set_title('Loss')\n",
        "            axes[0].plot(self.log_dict[\"train_loss\"], label='train')\n",
        "            axes[0].plot(self.log_dict[\"val_loss\"], label='validate')\n",
        "            axes[0].legend()\n",
        "\n",
        "            axes[1].set_title('Accuracy')\n",
        "            axes[1].plot(self.log_dict[\"train_score\"], label='train')\n",
        "            axes[1].plot(self.log_dict[\"val_score\"], label='validate')\n",
        "            axes[1].legend()\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "    def train(self, train_loader, val_loader, n_epochs, visualize=True, model=None, opt=None, criterion=None, metric=None):\n",
        "        self.visualize = visualize\n",
        "        self.opt = (opt or self.opt)\n",
        "        self.model = (model or self.model)\n",
        "        self.criterion = (criterion or self.criterion)\n",
        "        self.metric = (metric or self.metric)\n",
        "        self.model.train(self.train_phase)\n",
        "\n",
        "        for _epoch in range(n_epochs):\n",
        "            start_time = time.time()\n",
        "            self.epoch += 1\n",
        "            print(f\"epoch {self.epoch:3d}/{n_epochs:3d} started\")\n",
        "\n",
        "            self.train_phase = True\n",
        "            self._run_epoch(train_loader)\n",
        "\n",
        "            print(f\"epoch {self.epoch:3d}/{n_epochs:3d} took {time.time() - start_time:.2f}s\")\n",
        "\n",
        "            self.train_phase = False\n",
        "            self.validate(val_loader)\n",
        "            self.save_checkpoint()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def validate(self, loader, model=None):\n",
        "        self.train_phase = False\n",
        "        self.model.train(self.train_phase)\n",
        "        self._run_epoch(loader)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def predict(self, X=None, loader=None):\n",
        "        self.load_checkpoint()\n",
        "        self.train_phase = False\n",
        "        self.model.train(self.train_phase)\n",
        "        if loader:\n",
        "            pred_label = []\n",
        "            for X_batch in tqdm(loader, desc='Test', leave=False):\n",
        "                X_batch = X_batch.to(self.device)\n",
        "                self.logits = self.forward(X_batch)\n",
        "                y_pred = torch.max(F.softmax(self.logits, dim=1), dim=1)[1]\n",
        "                pred_label.append(y_pred.item())\n",
        "        if X:\n",
        "            self.logits = self.forward(X)\n",
        "            pred_label = torch.max(F.softmax(self.logits, dim=1), dim=1)[1]\n",
        "\n",
        "        return pred_label\n"
      ],
      "metadata": {
        "id": "-qfWB8R6SVjl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sE8nk6sKP1jP"
      },
      "outputs": [],
      "source": [
        "# Your experiments here"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tAA9Xnz7_cXF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}